{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "from seaborn import heatmap, lineplot, clustermap\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from etm import ETM\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouse pancreas single-cell dataset\n",
    "# read in data and cell type labels\n",
    "with open('data/MP.pickle', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "with open('data/MP_genes.pickle', 'rb') as f:\n",
    "    genes = pickle.load(f)\n",
    "    \n",
    "df.set_index('Unnamed: 0', inplace=True)  # set first column (cell ID as the index column)\n",
    "sample_id = pickle.load(open('data/cell_IDs.pkl', 'rb'))\n",
    "df = df.loc[list(sample_id), :]\n",
    "\n",
    "X = df[genes].values  # extract the N x M cells-by-genes matrix\n",
    "\n",
    "sample_info = pd.read_csv('data/sample_info.csv')\n",
    "\n",
    "mp_anndata = anndata.AnnData(X=X)\n",
    "\n",
    "mp_anndata.obs['Celltype'] = sample_info['assigned_cluster'].values\n",
    "\n",
    "N = X.shape[0]  # number of single-cell samples\n",
    "K = 16  # number of topics\n",
    "M = X.shape[1]  # number of genes\n",
    "\n",
    "X_tensor = torch.from_numpy(np.array(X, dtype=\"float32\"))\n",
    "sums = X_tensor.sum(1).unsqueeze(1)\n",
    "X_tensor_normalized = X_tensor / sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ari(cell_embed, adata):\n",
    "    \"\"\"\n",
    "        This function is used to evaluate ARI using the lower-dimensional embedding\n",
    "        cell_embed of the single-cell data\n",
    "        :param cell_embed: a NxK single-cell embedding generated from NMF or scETM\n",
    "        :param adata: single-cell AnnData data object (default to to mp_anndata)\n",
    "        :return: ARI score of the clustering results produced by Louvain\n",
    "    \"\"\"\n",
    "    adata.obsm['cell_embed'] = cell_embed\n",
    "    sc.pp.neighbors(adata, use_rep=\"cell_embed\", n_neighbors=30)\n",
    "    sc.tl.louvain(adata, resolution=0.15)\n",
    "    ari = adjusted_rand_score(adata.obs['Celltype'], adata.obs['louvain'])\n",
    "    return ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ETM(num_topics=K,\n",
    "            vocab_size=len(genes),\n",
    "            t_hidden_size=256,\n",
    "            rho_size=256,\n",
    "            theta_act='relu',\n",
    "            embeddings=None,\n",
    "            train_embeddings=True,\n",
    "            enc_drop=0.5).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1.2e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the VAE for one epoch\n",
    "def train_scETM_helper(model, X_tensor, X_tensor_normalized):\n",
    "    # initialize the model and loss\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    model.zero_grad()\n",
    "\n",
    "    # forward and backward pass\n",
    "    nll, kl_theta = model(X_tensor, X_tensor_normalized)\n",
    "    loss = nll + kl_theta\n",
    "    loss.backward()  # backprop gradients w.r.t. negative ELBO\n",
    "\n",
    "    # clip gradients to 2.0 if it gets too large\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
    "\n",
    "    # update model to minimize negative ELBO\n",
    "    optimizer.step()\n",
    "\n",
    "    return torch.sum(loss).item()\n",
    "\n",
    "\n",
    "# get sample encoding theta from the trained encoder network\n",
    "def get_theta(model, input_x):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        q_theta = model.q_theta(input_x)\n",
    "        mu_theta = model.mu_q_theta(q_theta)\n",
    "        theta = F.softmax(mu_theta, dim=-1)\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 Train ETM on mouse pancreas scRNA-seq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_scETM(model, X_tensor, X_tensor_normalized, adata=mp_anndata, niter=1000):\n",
    "    \"\"\"\n",
    "        :param model: the scETM model object\n",
    "        :param X_tensor: NxM raw read count matrix X\n",
    "        :param X_tensor_normalized: NxM normalized read count matrix X\n",
    "        :param adata: annotated single-cell data object with ground-truth cell type information for evaluation\n",
    "        :param niter: maximum number of epochs\n",
    "        :return:\n",
    "            1. model: trained scETM model object\n",
    "            2. perf: niter-by-3 ndarray with iteration index, NELBO, and ARI as the 3 columns\n",
    "    \"\"\"\n",
    "    perf = np.ndarray(shape=(niter, 3), dtype='float')\n",
    "    \n",
    "    # WRITE YOUR CODE HERE\n",
    "    \n",
    "    return model, perf\n",
    "\n",
    "def monitor_perf(perf, objective, path=\"\"):\n",
    "    \"\"\"\n",
    "    :param perf: niter-by-3 ndarray with iteration index, objective function, and ARI as the 3 columns\n",
    "    :param objective: 'NELBO'\n",
    "    :param path: path to save the figure if not display to the screen\n",
    "    :behaviour: display or save a 2-by-1 plot showing the progress of optimizing objective and ARI as\n",
    "        a function of iterations\n",
    "    \"\"\"\n",
    "    # WRITE YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, scetm_perf = train_scETM(model, X_tensor, X_tensor_normalized, niter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_perf(scetm_perf, \"NELBO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 Plot t-SNE or UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 plot cells by topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 Plot genes-by-topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
